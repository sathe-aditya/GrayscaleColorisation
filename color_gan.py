# -*- coding: utf-8 -*-
"""Color GAN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gLunFF634IVUm3I10JJfPuU3RIuyJASM
"""

from __future__ import print_function
import argparse
import os
import sys
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
cudnn.benchmark = True
cudnn.fastest = True
import torch.optim as optim
import torchvision.utils as vutils
from torch.autograd import Variable
import numpy as np
from PIL import Image, ImageOps, ImageFilter
import torch.utils.data as data

import cv2

data_path = ''

parser = dict()
parser['dataset'] = 'dataset',
parser['dataroot'] = 'train'
parser['valDataroot'] ='val'
parser['mode'] = 'A2B'
parser['batchSize'] = 32
parser['valBatchSize'] = 64
parser['originalSize'] = 256
parser['imageSize'] = 128
parser['inputChannelSize'] = 1
parser['outputChannelSize'] = 3 #CHANGE THIS TO 1 for L, U, V; 3 for RGB
parser['model'] = "E2C" # KEEP E2G for L, U, V; CHANGE TO E2C for RBG
parser['ngf'] = 64
parser['ndf'] = 64
parser['niter'] = 10000
parser['lrD'] = 0.0002
parser['lrG'] = 0.0002
parser['lambdaGAN'] = 1
parser['lambdaIMG'] = 100
parser['wd'] = 0.0000
parser['beta1'] = 0.5
parser['rmsprop'] = 'store_true'
parser['netG'] = ''
parser['netD'] = ''
parser['workers'] = 2
parser['exp'] =''
parser['display'] = 5
parser['evalIter'] = 100
parser['cuda'] = True
parser['patchGAN'] = False
opt = parser

def blockUNet(in_c, out_c, name, transposed=False, bn=True, relu=True, dropout=False, kernels=4, stride=2, padding=1):
  block = nn.Sequential()
  if relu:
    block.add_module('%srelu' % name, nn.ReLU(inplace=True))
  else:
    block.add_module('%sleakyrelu' % name, nn.LeakyReLU(0.2, inplace=True))
  if not transposed:
    block.add_module('%sconv' % name, nn.Conv2d(in_c, out_c, kernels, stride, padding, bias=False))
  else:
    block.add_module('%stconv' % name, nn.ConvTranspose2d(in_c, out_c, kernels, stride, padding, bias=False))
  if bn:
    block.add_module('%sbn' % name, nn.BatchNorm2d(out_c))
  if dropout:
    block.add_module('%sdropout' % name, nn.Dropout2d(0.5, inplace=True))
  return block

class D_scalar(nn.Module):
    def __init__(self, nc, nf):
        super(D_scalar, self).__init__()
        layer_idx = 0
        main = nn.Sequential()
        # 256 x 256
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, nn.Conv2d(nc, nf, 4, 2, 1, bias=False))
        # input is 128 x 128
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf, nf*2, name, transposed=False, bn=True, relu=False, dropout=False))
        # input is 64 x 64
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf*2, nf*4, name, transposed=False, bn=True, relu=False, dropout=False))
        # input is 32 x 32
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf*4, nf*8, name, transposed=False, bn=True, relu=False, dropout=False))
        # input is 16 x 16
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf*8, nf*8, name, transposed=False, bn=True, relu=False, dropout=False))

        # input in 8 x 8
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf*8, nf*8, name, transposed=False, bn=True, relu=False, dropout=False))

        # input is 4 x 4
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module(name, blockUNet(nf*8, nf*8, name, transposed=False, bn=True, relu=False, dropout=False))
        # input is 2 x 2
        layer_idx += 1
        name = 'layer%d' % layer_idx
        main.add_module('%sleakyrelu' % name, nn.LeakyReLU(0.2, inplace=True))
        main.add_module('%sconv' % name, nn.Conv2d(nf*8, 1, 2, 1, 0, bias=False))
        main.add_module('%ssigmoid' % name , nn.Sigmoid())
        # 1 x 1
        self.main = main

    def forward(self, x):
        output = self.main(x)
        return output

class D(nn.Module):
  def __init__(self, nc, nf):
    super(D, self).__init__()

    main = nn.Sequential()
    # 256   128
    layer_idx = 1
    name = 'layer%d' % layer_idx
    main.add_module('%sconv' % name, nn.Conv2d(nc, nf, 4, 2, 1, bias=False))

    # 128   64
    layer_idx += 1 
    name = 'layer%d' % layer_idx
    main.add_module(name, blockUNet(nf, nf*2, name, transposed=False, bn=True, relu=False, dropout=False))

    # 64    UNCOMMENT FOR 256x256
    layer_idx += 1 
    name = 'layer%d' % layer_idx
    nf = nf * 2
    main.add_module(name, blockUNet(nf, nf*2, name, transposed=False, bn=True, relu=False, dropout=False))

    # 32    
    layer_idx += 1 
    name = 'layer%d' % layer_idx
    nf = nf * 2
    main.add_module('%sleakyrelu' % name, nn.LeakyReLU(0.2, inplace=True))
    main.add_module('%sconv' % name, nn.Conv2d(nf, nf*2, 4, 1, 1, bias=False))
    main.add_module('%sbn' % name, nn.BatchNorm2d(nf*2))

    # 31
    layer_idx += 1 
    name = 'layer%d' % layer_idx
    nf = nf * 2
    main.add_module('%sleakyrelu' % name, nn.LeakyReLU(0.2, inplace=True))
    main.add_module('%sconv' % name, nn.Conv2d(nf, 1, 4, 1, 1, bias=False))
    main.add_module('%ssigmoid' % name , nn.Sigmoid())
    # 30 (sizePatchGAN=30)

    self.main = main

  def forward(self, x):
    output = self.main(x)
    return output

class G(nn.Module):
  def __init__(self, input_nc, output_nc, nf):
    super(G, self).__init__()

    # input is 256 x 256    128x128
    layer_idx = 1
    name = 'layer%d' % layer_idx
    layer1 = nn.Sequential()
    layer1.add_module(name, nn.Conv2d(input_nc, nf, 4, 2, 1, bias=False))
    # input is 128 x 128    64x64
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer2 = blockUNet(nf, nf*2, name, transposed=False, bn=True, relu=False, dropout=False)
    # input is 64 x 64  32x32
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer3 = blockUNet(nf*2, nf*4, name, transposed=False, bn=True, relu=False, dropout=False)
    # input is 32   16
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer4 = blockUNet(nf*4, nf*8, name, transposed=False, bn=True, relu=False, dropout=False)
    # input is 16   8
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer5 = blockUNet(nf*8, nf*8, name, transposed=False, bn=True, relu=False, dropout=False)
    # input is 8    4
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer6 = blockUNet(nf*8, nf*8, name, transposed=False, bn=True, relu=False, dropout=False)
    # input is 4    2
    layer_idx += 1
    name = 'layer%d' % layer_idx
    layer7 = blockUNet(nf*8, nf*8, name, transposed=False, bn=False, relu=False, dropout=False) # BN TRUE FOR 256x256
    # input is 2 x 2   1x1

    ## NOT NEEDED FOR 128 x 128 INPUT
    # layer_idx += 1
    # name = 'layer%d' % layer_idx
    # layer8 = blockUNet(nf*8, nf*8, name, transposed=False, bn=False, relu=False, dropout=False)

    ## NOTE: decoder
    # input is 1
    # name = 'dlayer%d' % layer_idx
    # d_inc = nf*8
    # dlayer8 = blockUNet(d_inc, nf*8, name, transposed=True, bn=True, relu=True, dropout=True)

    #import pdb; pdb.set_trace()
    # input is 2    1
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*8
    # d_inc = nf*8*2
    dlayer7 = blockUNet(d_inc, nf*8, name, transposed=True, bn=True, relu=True, dropout=True)
    # input is 4    2
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*8*2
    dlayer6 = blockUNet(d_inc, nf*8, name, transposed=True, bn=True, relu=True, dropout=True)
    # input is 8    4
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*8*2
    dlayer5 = blockUNet(d_inc, nf*8, name, transposed=True, bn=True, relu=True, dropout=False)
    # input is 16   8
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*8*2
    dlayer4 = blockUNet(d_inc, nf*4, name, transposed=True, bn=True, relu=True, dropout=False)
    # input is 32   16
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*4*2
    dlayer3 = blockUNet(d_inc, nf*2, name, transposed=True, bn=True, relu=True, dropout=False)
    # input is 64   32
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    d_inc = nf*2*2
    dlayer2 = blockUNet(d_inc, nf, name, transposed=True, bn=True, relu=True, dropout=False)
    # input is 128  64
    layer_idx -= 1
    name = 'dlayer%d' % layer_idx
    dlayer1 = nn.Sequential()
    d_inc = nf*2
    dlayer1.add_module('%srelu' % name, nn.ReLU(inplace=True))
    dlayer1.add_module('%stconv' % name, nn.ConvTranspose2d(d_inc, output_nc, 4, 2, 1, bias=False))
    dlayer1.add_module('%stanh' % name, nn.Tanh())

    self.layer1 = layer1
    self.layer2 = layer2
    self.layer3 = layer3
    self.layer4 = layer4
    self.layer5 = layer5
    self.layer6 = layer6
    self.layer7 = layer7
    # self.layer8 = layer8
    # self.dlayer8 = dlayer8
    self.dlayer7 = dlayer7
    self.dlayer6 = dlayer6
    self.dlayer5 = dlayer5
    self.dlayer4 = dlayer4
    self.dlayer3 = dlayer3
    self.dlayer2 = dlayer2
    self.dlayer1 = dlayer1

  def forward(self, x):
    out1 = self.layer1(x)
    out2 = self.layer2(out1)
    out3 = self.layer3(out2)
    out4 = self.layer4(out3)
    out5 = self.layer5(out4)
    out6 = self.layer6(out5)

    out7 = self.layer7(out6)
    # out8 = self.layer8(out7)
    # dout8 = self.dlayer8(out8)
    # dout8_out7 = torch.cat([dout8, out7], 1)
    dout7 = self.dlayer7(out7) #dout8_dout7 for 256x256
    dout7_out6 = torch.cat([dout7, out6], 1)
    dout6 = self.dlayer6(dout7_out6)
    dout6_out5 = torch.cat([dout6, out5], 1)
    dout5 = self.dlayer5(dout6_out5)
    dout5_out4 = torch.cat([dout5, out4], 1)
    dout4 = self.dlayer4(dout5_out4)
    dout4_out3 = torch.cat([dout4, out3], 1)
    dout3 = self.dlayer3(dout4_out3)
    dout3_out2 = torch.cat([dout3, out2], 1)
    dout2 = self.dlayer2(dout3_out2)
    dout2_out1 = torch.cat([dout2, out1], 1)
    dout1 = self.dlayer1(dout2_out1)
    return dout1

class AverageMeter(object):
  """Computes and stores the average and current value"""
  def __init__(self):
      self.reset()

  def reset(self):
    self.val = 0
    self.avg = 0
    self.sum = 0
    self.count = 0

  def update(self, val, n=1):
    self.val = val
    self.sum += val * n
    self.count += n
    self.avg = self.sum / self.count

class Compose(object):
  """Composes several transforms together.
  Args:
    transforms (List[Transform]): list of transforms to compose.
  Example:
    >>> transforms.Compose([
    >>>   transforms.CenterCrop(10),
    >>>   transforms.ToTensor(),
    >>> ])
  """
  def __init__(self, transforms):
    self.transforms = transforms

  def __call__(self, imgA, imgB):
    for t in self.transforms:
      imgA, imgB = t(imgA, imgB)
    return imgA, imgB
  
class ToTensor(object):
  def __call__(self, picA, picB):
    pics = [picA, picB]
    output = []
    for pic in pics:
      if isinstance(pic, np.ndarray):
        img = torch.from_numpy(pic.transpose((2, 0, 1)))
      else:
        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
        if pic.mode == 'YCbCr':
          nchannel = 3
        else:
          nchannel = len(pic.mode)
        img = img.view(pic.size[1], pic.size[0], nchannel)
        img = img.transpose(0, 1).transpose(0, 2).contiguous()
        img = img.float().div(255.)
      output.append(img)
    return output[0], output[1]

class Normalize(object):
  def __init__(self, mean, std):
    self.mean = mean
    self.std = std

  def __call__(self, tensorA, tensorB):
    tensors = [tensorA, tensorB]
    output = []
    for tensor in tensors:
      for t, m, s in zip(tensor, self.mean, self.std):
        t.sub_(m).div_(s)
      output.append(tensor)
    return output[0], output[1]

class Scale(object):
  def __init__(self, size, interpolation=Image.BILINEAR, model="E2C"): # CHANGE MODEL HERE!!!!!
    self.size = size
    self.model = model
    self.interpolation = interpolation

  def __call__(self, imgA, imgB):
    imgs = [imgA, imgB]
    output = []
    for img in imgs:
      w, h = img.size
      if (w <= h and w == self.size) or (h <= w and h == self.size):
        output.append(img)
        continue
      if w < h:
        ow = self.size
        oh = int(self.size * h / w)
        output.append(img.resize((ow, oh), self.interpolation))
        continue
      else:
        oh = self.size
        ow = int(self.size * w / h)
      output.append(img.resize((ow, oh), self.interpolation))
    if self.model == "E2G" or self.model == "Z2E" or self.model == "Z2G":
      output[1] = output[1].convert('L') # 1 channel gray
      output[0] = output[0].convert('L') # 1 channel edge
    elif self.model == "G2C":
      output[0] = output[1].convert('L') # 1 channel gray output
    return output[0], output[1]

IMG_EXTENSIONS = [
  '.jpg', '.JPG', '.jpeg', '.JPEG',
  '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',
]

def is_image_file(filename):
  return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)

def make_dataset(dir):
  images, image_names = [], []
  if not os.path.isdir(dir):
    raise Exception('Check dataroot')
  for root, _, fnames in sorted(os.walk(dir)):
    for fname in fnames:
      if is_image_file(fname):
        image_names.append(fname.split('.')[0])
        path = os.path.join(dir, fname)
        item = path
        images.append(item)
  return images, image_names



def default_loader(path):
  return Image.open(path)

class pix2pix_dataset(data.Dataset):
  def __init__(self, sourceroot, targetroot, transform=None, loader=default_loader, seed=None, batchSize=0, model=''):
    imgs, image_names = make_dataset(sourceroot)
    self.targetroot = targetroot
    self.sourceroot = sourceroot
    print("{} images found".format(len(imgs)))
    if len(imgs) == 0:
      raise(RuntimeError("Found 0 images in subfolders of: " + sourceroot + "\n"
                 "Supported image extensions are: " + ",".join(IMG_EXTENSIONS)))
    self.imgs = imgs
    self.image_names = image_names
    self.transform = transform
    self.loader = loader
    self.epoch = 1
    self.totalimages = len(imgs)
    self.iteration = 0
    self.model = model

    if seed is not None:
      np.random.seed(seed)

  def __getitem__(self, index):
    path = self.imgs[index]
    image_name = self.image_names[index]


    if self.iteration == self.totalimages:
      self.iteration = 0
      self.epoch += 1
    self.iteration += 1

    imgA = self.loader(os.path.join(self.sourceroot, image_name+'.jpg'))
    imgB = self.loader(os.path.join(self.targetroot, image_name+'.jpg'))

    if self.transform is not None:
      imgA, imgB = self.transform(imgA, imgB)
      return imgA, imgB

  def __len__(self):
    return len(self.imgs)

def getLoader(datasetName, sourcedataroot, targetdataroot, originalSize, imageSize, model, batchSize=64, workers=4,
              mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), split='train', shuffle=True, seed=None):

  if datasetName != 'folder':
    if split == 'train':
      dataset = pix2pix_dataset(sourceroot=sourcedataroot,
                              targetroot = targetdataroot,
                              transform=Compose([
                                Scale(originalSize),
                                ToTensor(),
                                Normalize(mean, std),
                              ]),
                              seed=seed,
                              model=model)
    else:
      dataset = pix2pix_dataset(sourceroot=sourcedataroot,
                              targetroot = targetdataroot,
                            transform=Compose([
                              Scale(originalSize),
                              ToTensor(),
                              Normalize(mean, std),
                             ]),
                             seed=seed,
                             model=model)

  assert dataset
  dataloader = torch.utils.data.DataLoader(dataset,
                                           batch_size=batchSize,
                                           shuffle=shuffle,
                                           num_workers=int(workers))
  return dataloader

def check_cuda(opt):
  if torch.cuda.is_available() and not opt['cuda']:
    print("WARNING: You have a CUDA device, so you should probably run with --cuda")
    opt['cuda'] = True
  return opt

def weights_init(m):
  classname = m.__class__.__name__
  if classname.find('Conv') != -1:
    m.weight.data.normal_(0.0, 0.02)
  elif classname.find('BatchNorm') != -1:
    m.weight.data.normal_(1.0, 0.02)
    m.bias.data.fill_(0)

def accuracy(output, target, topk=(1,)):
  maxk = max(topk)
  batch_size = target.size(0)

  _, pred = output.topk(maxk, 1, True, True)
  pred = pred.t()
  correct = pred.eq(target.view(1, -1).expand_as(pred))

  res = []
  for k in topk:
    correct_k = correct[:k].view(-1).float().sum(0)
    res.append(correct_k.mul_(100.0 / batch_size))
  return res

class ImagePool:
  def __init__(self, pool_size=50):
    self.pool_size = pool_size
    if pool_size > 0:
      self.num_imgs = 0
      self.images = []

  def query(self, image):
    if self.pool_size == 0:
      return image
    if self.num_imgs < self.pool_size:
      self.images.append(image.clone())
      self.num_imgs += 1
      return image
    else:
      if np.random.uniform(0,1) > 0.5:
        random_id = np.random.randint(self.pool_size, size=1)[0]
        tmp = self.images[random_id].clone()
        self.images[random_id] = image.clone()
        return tmp
      else:
        return image

def adjust_learning_rate(optimizer, init_lr, epoch, factor, every):
  lrd = init_lr / every
  old_lr = optimizer.param_groups[0]['lr']
  lr = old_lr - lrd
  if lr < 0: lr = 0
  for param_group in optimizer.param_groups:
    param_group['lr'] = lr

opt['manualSeed'] = 101
random.seed(opt['manualSeed'])
torch.manual_seed(opt['manualSeed'])
print("Random Seed: ", opt['manualSeed'])

# train/L is the source ALWAYS
# train/U (U component), train/V (V component), train/orig (RGB images) are targets ALWAYS
dataloader = getLoader(opt['dataset'],
                       'dataset/train/L', # SOURCE
                       'dataset/train/orig', # TARGET
                       opt['originalSize'],
                       opt['imageSize'],
                       opt['model'],
                       opt['batchSize'],
                       opt['workers'],
                       mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),
                       split='train',
                       shuffle=True,
                       seed=opt['manualSeed'])
valDataloader = getLoader(opt['dataset'],
                          'dataset/val/L', # SOURCE
                          'dataset/val/orig', # TARGET
                          opt['imageSize'], #opt['originalSize'],
                          opt['imageSize'],
                          opt['model'],
                          opt['valBatchSize'],
                          opt['workers'],
                          mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),
                          split='val',
                          shuffle=False,
                          seed=opt['manualSeed'])

# Commented out IPython magic to ensure Python compatibility.
trainLogger = open('%s/train.log' % opt['exp'], 'w')

ngf = opt['ngf']
ndf = opt['ndf']
inputChannelSize = opt['inputChannelSize']
outputChannelSize= opt['outputChannelSize']

# get models
netG = G(inputChannelSize, outputChannelSize, ngf)
netG.apply(weights_init)
start_epoch = 0
if opt['netG'] != '':
  netG.load_state_dict(torch.load(opt['netG']))
  start_epoch = int(opt['netD'].split('_')[-1].split('.')[0])
print(netG)
if opt['patchGAN']:
  netD = D(inputChannelSize + outputChannelSize, ndf)
else:
  netD = D_scalar(inputChannelSize + outputChannelSize, ndf)
netD.apply(weights_init)
if opt['netD'] != '':
  netD.load_state_dict(torch.load(opt['netD']))
print(netD)

netG.train()
netD.train()
criterionBCE = nn.BCELoss()
criterionCAE = nn.L1Loss()

target= torch.FloatTensor(opt['batchSize'], outputChannelSize, opt['imageSize'], opt['imageSize'])
input = torch.FloatTensor(opt['batchSize'], inputChannelSize, opt['imageSize'], opt['imageSize'])
val_target= torch.FloatTensor(opt['valBatchSize'], outputChannelSize, opt['imageSize'], opt['imageSize'])
val_input = torch.FloatTensor(opt['valBatchSize'], inputChannelSize, opt['imageSize'], opt['imageSize'])
label_d = torch.FloatTensor(opt['batchSize'])
sizePatchGAN = 30
real_label = 1
fake_label = 0
lambdaGAN = opt['lambdaGAN']
lambdaIMG = opt['lambdaIMG']

if opt['cuda']:
  netD.cuda()
  netG.cuda()
  criterionBCE.cuda()
  criterionCAE.cuda()
  target, input, label_d = target.cuda(), input.cuda(), label_d.cuda()
  val_target, val_input = val_target.cuda(), val_input.cuda()

target = Variable(target)
input = Variable(input)
label_d = Variable(label_d)

val_iter = iter(valDataloader)
data_val = val_iter.next()
if opt['mode'] == 'B2A':
  val_target_cpu, val_input_cpu = data_val
elif opt['mode'] == 'A2B':
  val_input_cpu, val_target_cpu = data_val

if opt['cuda']:
  val_target_cpu, val_input_cpu = val_target_cpu.cuda(), val_input_cpu.cuda()
val_target.resize_as_(val_target_cpu).copy_(val_target_cpu)
val_input.resize_as_(val_input_cpu).copy_(val_input_cpu)
vutils.save_image(val_target, '%s/real_target.png' % opt['exp'], normalize=True)
vutils.save_image(val_input, '%s/real_input.png' % opt['exp'], normalize=True)

if opt['rmsprop']:
  optimizerD = optim.RMSprop(netD.parameters(), lr = opt['lrD'])
  optimizerG = optim.RMSprop(netG.parameters(), lr = opt['lrG'])
else:
  optimizerD = optim.Adam(netD.parameters(), lr = opt['lrD'], betas = (opt['beta1'], 0.999), weight_decay=opt['wd'])
  optimizerG = optim.Adam(netG.parameters(), lr = opt['lrG'], betas = (opt['beta1'], 0.999), weight_decay=0.0)

ganIterations = 0
for epoch in range(start_epoch + 1, opt['niter']):
  for i, data in enumerate(dataloader, 0):
    if opt['mode'] == 'B2A':
      target_cpu, input_cpu = data
    elif opt['mode'] == 'A2B' :
      input_cpu, target_cpu = data
    batch_size = target_cpu.size(0)

    if opt['cuda']:
      target_cpu, input_cpu = target_cpu.cuda(), input_cpu.cuda()
    with torch.no_grad():
      target.resize_as_(target_cpu).copy_(target_cpu)
      input.resize_as_(input_cpu).copy_(input_cpu)

    for p in netD.parameters():
      p.requires_grad = True
    netD.zero_grad()

    with torch.no_grad():
      if opt['patchGAN']:
        label_d.resize_((batch_size, 1, sizePatchGAN, sizePatchGAN)).fill_(real_label)
      else:
        label_d.resize_((batch_size, 1, 1, 1)).fill_(real_label)
    output = netD(torch.cat([target, input], 1))
    errD_real = criterionBCE(output, label_d)
    errD_real.backward()
    D_x = output.data.mean()
    x_hat = netG(input)
    fake = x_hat.detach()
    with torch.no_grad():
      label_d.fill_(fake_label)
    output = netD(torch.cat([fake, input], 1))
    errD_fake = criterionBCE(output, label_d)
    errD_fake.backward()
    D_G_z1 = output.data.mean()
    errD = errD_real + errD_fake
    optimizerD.step()

    for p in netD.parameters():
      p.requires_grad = False
    netG.zero_grad() 

    L_img_ = criterionCAE(x_hat, target)
    L_img = lambdaIMG * L_img_
    if lambdaIMG != 0:
      L_img.backward(retain_graph=True)

    with torch.no_grad():
      label_d.fill_(real_label)
    output = netD(torch.cat([x_hat, input], 1))
    errG_ = criterionBCE(output, label_d)
    errG = lambdaGAN * errG_
    if lambdaGAN != 0:
      errG.backward()
    D_G_z2 = output.data.mean()

    optimizerG.step()
    ganIterations += 1

    if ganIterations % opt['display'] == 0:
      print('[%d/%d][%d/%d] L_D: %f L_img: %f L_G: %f D(x): %f D(G(z)): %f / %f'
#           % (epoch, opt['niter'], i, len(dataloader),
             errD.item(), 
             L_img.item(), 
             errG.item(), 
             D_x, 
             D_G_z1.item(), 
             D_G_z2.item()))
      sys.stdout.flush()
      trainLogger.write('%d\t%f\t%f\t%f\t%f\t%f\t%f\n' % \
                        (i, errD.item(), errG.item(), L_img.item(), D_x, D_G_z1, D_G_z2))
      trainLogger.flush()
      if ganIterations % opt['evalIter'] == 0:
          val_batch_output = torch.FloatTensor(val_target.size()).fill_(0)
          for idx in range(val_input.size(0)):
              single_img = val_input[idx,:,:,:].unsqueeze(0)
              val_inputv = Variable(single_img)
              x_hat_val = netG(val_inputv)
              val_batch_output[idx,:,:,:].unsqueeze(0).copy_(x_hat_val.data)
          vutils.save_image(val_batch_output, '%s/output/generated_epoch_%08d_iter%08d.png' % \
                              (opt['exp'], epoch, ganIterations), normalize=True)

  torch.save(netG.state_dict(), '%s/netG_%s.pth' % (opt['exp'], opt['model']))
  torch.save(netD.state_dict(), '%s/netD_%s.pth' % (opt['exp'], opt['model']))
trainLogger.close()

